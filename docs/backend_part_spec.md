<!-- style: modern -->
<!-- use: mathjax -->
# 部分后端技术模块

## 模块简介


```
#include <stdio.h>

int main
{
    printf("Hello, world!");
    return 0;
}
```

## TeX公式

$C_3^2$

$$ \arcsin ^{ \alpha  }{ x } $$

## 另一种方式

\\[ arcsin ^{ \alpha }{ x }  \\]
\\( \arcsin ^{ \alpha }{ x } \\)

### 后端核心模块

- forerunner: 根据配置文件绘制网站地图
- spider: 并行下载器，根据网站地图增量式的下载网页正文，并负责转码
- parser: 提取网页正文信息

### 用到的开发技术

C++， 正则表达式， Javascript解释器， XML， Qt框架库

### 工具模块

- configtool: 图形化编辑工具，帮助运营人员配置网站的爬虫规则和parser规则
- generator: 根据网站地图构造网站的物理结构，生成索引信息
- javascriptDebuggr: 用来测试javascript代码对目标文本的匹配程度，已废弃，合并到了configtool工具中

## 各模块详细介绍

### Forerunner

根据配置文件绘制网站地图

#### 参数

- version: 输出模块版本号
- log-file: 日志文件存放路径，默认为当前文件夹
- rule-dir: 规则文件存放路径
- shared-dir: 存放生成的网站地图的路径

#### 输出

网站地图文件 dir.xml

#### 实现流程

- 载入网站配置文件
- 设置分析器线程数
- 设置目标网站字符编码
- 根据规则文件爬行网站，自动扩展规则，生成网站地图
- 将网站地图输出到dir.xml文件，并将所有的字符串全部转换成utf-8编码


#### 如何处理环形连接

在内存中建立一个set，将处理过的url存入set，如果url已经处理过就丢弃，避免进入环型结构无法跳出

#### 如何处理站外连接

通过比较根域名，如果属于站外连接直接丢弃

### 网站配置文件

因为我们的爬虫与通用的爬虫不太一样，不是每个连接都要抓取，所以需要为每个网站定制爬行的范围和爬行规则

#### 核心数据结构解释

##### Website 

描述网站的整体信息，包括编辑人，网站描述信息，爬行时段，爬行线程数，网站编码等。

##### Node 

描述一个网页的信息，包括URL，标题，刷新率，显示排版的优先级，子节点的匹配规则列表。

##### Rule 

描述一个匹配规则，包括寻找下一页的规则，获取正文中网页标题和连接的规则，还可以自动扩展新规则，规则可以继承给子规则，可以限制规则匹配的最大节点数量。

##### Expression

描述一个具体的匹配表达式， 支持正则文法和Javascript表达式，支持执行单次和递归执行。

#### 具体设计思路

因为规则在半个小时内很难描述清楚，而且并不是十分复杂，可以通过阅读xml文件并和牟文杰交流来熟悉配置文件的设计思路。

### Spider

根据网站地图，并发下载网页正文文件

#### 参数

- version: 输出模块版本号
- log-file: 日志文件存放路径:  默认为当前文件夹
- worker-dir: 下载的网页正文的保存路径
- dir-file: 网站地图的存放路径

#### 输出

下载的网页正文文件 （全部转换成utf-8编码）

#### 实现流程

- 读取网站地图文件
- 设置网站字符编码
- 设置并发下载数，默认为10
- 开始下载

#### 增量下载策略

通过增量的方式对数据进行更新，只处理新增的数据，从而加快处理速度，减少网络流量，进而减少运行成本。

##### 实现方式

将需要下载的url进行hash运算，用hash值匹配本地文件系统，看是否已经存在，如果存在就跳过，下载下一个url

### Parser

踢出网页正文中的无用信息，提取富文本信息

#### 参数

- version: 输出模块版本号
- log-file: 日志文件存放路径： 默认为当前文件夹
- worker-dir: 分析后的网页的存放路径
- shared-dir: 网站地图的存放路径
- rule-dir: 网站parser规则文件的存放路径
- source-dir: spider下载的网页的存放路径

#### 输出

处理后的网页正文文件

#### 实现流程

- 打开parser规则文件，读取规则
- 进入原始网页文件的存放文件夹
- 递归的对每一个文件调用parser规则，提取富文本信息，删除与内容无关的字符
- 生成新的正文文件并保存

#### 提取后的结构

- title
- author;
- lastModified; //mseconds since Epoch
- bodyData;
- url;
- 富文本信息列表;

## 工具模块简介

- configtool: 图形化编辑工具，帮助运营人员配置网站的爬虫规则和parser规则
- generator: 根据网站地图构造网站的物理结构，生成索引信息

## 可能遇到的问题

### 规则文件不知道怎么写

- 首先阅读文档并和牟文杰交流
- 参考我写的黑龙江政府网站的模板
- 阅读forerunner源代码

### 出现乱码

在网站配置文件中添加codec属性

### 如何设计规则

- 尝试正则表达式匹配
- 正则表达式无法解决的情况下通过Javascript编程解决
- 如果极其困难，因为我们把forerunner和spider分离，可以人工修改生成的网站地图文件来解决。

# end
